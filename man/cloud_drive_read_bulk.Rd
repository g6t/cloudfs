% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/drive_transfer_bulk.R
\name{cloud_drive_read_bulk}
\alias{cloud_drive_read_bulk}
\title{Read Google Drive contents in bulk}
\usage{
cloud_drive_read_bulk(
  content,
  fun = NULL,
  ...,
  quiet = FALSE,
  project = getwd()
)
}
\arguments{
\item{content}{(data.frame) Output of \code{cloud_drive_ls()}}

\item{fun}{Reading function. By default is \code{NULL} which means that it will
be attempted to guess an appropriate reading function from file extension.}

\item{...}{Further parameters to pass to \code{fun}.}

\item{quiet}{All caution messages may be turned off by setting this parameter
to \code{TRUE}.}

\item{project}{Path to a project. By default it is current working directory.}
}
\description{
\link{cloud_drive_ls} function returns a dataframe of contents of a
Google Drive folder. \code{cloud_drive_read_bulk} can be applied to such a
dataframe to read all the listed files into a named list. It will be
attempted to guess reading function from file extensions. You can pass
reading function manually by setting \code{fun} parameter, but it means that all
the files will be read using one function. In fact, you probably shouldn't
be reading multiple files of different types in bulk.

The workflow in mind is that you would call \code{cloud_drive_ls()}, then use
dplyr verbs to keep only files that you need and then call
\code{cloud_drive_read_bulk} on the result. Note that you don't need to filter
out folders -- it is done automatically.
}
\examples{
\dontrun{
data_lst <- 
  cloud_drive_ls("data") \%>\% 
  filter(type == "csv") \%>\% 
  cloud_drive_read_bulk()
}
  
}
