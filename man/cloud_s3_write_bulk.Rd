% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/s3_transfer_bulk.R
\name{cloud_s3_write_bulk}
\alias{cloud_s3_write_bulk}
\title{Write objects to S3 in bulk}
\usage{
cloud_s3_write_bulk(
  content,
  fun = NULL,
  ...,
  local = FALSE,
  quiet = FALSE,
  root = NULL
)
}
\arguments{
\item{content}{(data.frame) output of \code{cloud_object_ls()}}

\item{fun}{a function to write a file to cloud location to which x and a file
path will be passed (in that order). By default, if \code{fun = NULL}, it will
be attempted to find an appropriate writing function based on the file
extension.}

\item{...}{further parameters to pass to \code{fun}}

\item{local}{(logical) If \code{TRUE}, will additionally create a local file at
the corresponding path. Default is \code{FALSE}.}

\item{quiet}{all caution messages may be turned off by setting this parameter
to \code{TRUE}.}

\item{root}{S3 path of the project root. This serves as the reference point
for all relative paths. When left as \code{NULL}, the root is automatically
derived from the \code{cloudfs.s3} field of the project's DESCRIPTION file.}
}
\description{
Given a named list of objects \link{cloud_object_ls} function returns
a dataframe similar to the output of \link{cloud_local_ls} or \link{cloud_s3_ls}.
\code{cloud_s3_write_bulk} can be applied to such a dataframe to write all the
listed objects to S3. \link{cloud_s3_write} is used under the hood. It will be
attempted to guess writing function from file extensions. You can pass
writing function manually by setting \code{fun} parameter, but it means that all
the files will be written using one function. In fact, you probably
shouldn't be writing multiple files of different types in bulk.
}
\examples{
\dontrun{
# write two csv files: data/df_mtcars.csv and data/df_iris.csv
cloud_object_ls(
  dplyr::lst(mtcars = mtcars, iris = iris),
  path = "data",
  extension = "csv",
  prefix = "df_"
) \%>\% 
cloud_s3_write_bulk()
}
  
}
